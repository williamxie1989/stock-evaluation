# -*- coding: utf-8 -*-
"""
Optunaè¶…å‚æ•°ä¼˜åŒ–å™¨
è‡ªåŠ¨æœç´¢æœ€ä¼˜æ¨¡å‹è¶…å‚æ•°
"""

import numpy as np
import pandas as pd
from typing import Dict, Any, Optional, Callable, List
import logging
import warnings

# Optuna imports
try:
    import optuna
    from optuna.samplers import TPESampler, RandomSampler, CmaEsSampler
    from optuna.pruners import MedianPruner
    OPTUNA_AVAILABLE = True
except ImportError:
    OPTUNA_AVAILABLE = False
    warnings.warn("Optuna not installed. Install with: pip install optuna")

# Model imports
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import roc_auc_score, mean_squared_error, r2_score
import xgboost as xgb
import lightgbm as lgb

logger = logging.getLogger(__name__)


class OptunaOptimizer:
    """
    Optunaè¶…å‚æ•°ä¼˜åŒ–å™¨
    
    æ”¯æŒXGBoostå’ŒLightGBMçš„åˆ†ç±»/å›å½’ä»»åŠ¡
    ä½¿ç”¨æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ç¡®ä¿æ— æ•°æ®æ³„æ¼
    """
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        åˆå§‹åŒ–ä¼˜åŒ–å™¨
        
        Parameters
        ----------
        config : dict, optional
            é…ç½®å‚æ•°:
            - n_trials: ä¼˜åŒ–è¯•éªŒæ¬¡æ•° (default: 100)
            - timeout: è¶…æ—¶æ—¶é—´ç§’æ•° (default: 3600)
            - sampler: é‡‡æ ·å™¨ç±»å‹ ('tpe'/'random'/'cmaes', default: 'tpe')
            - cv_folds: äº¤å‰éªŒè¯æŠ˜æ•° (default: 5)
            - n_jobs: å¹¶è¡Œä»»åŠ¡æ•° (default: 1)
            - direction: ä¼˜åŒ–æ–¹å‘ ('maximize'/'minimize', default: 'maximize')
        """
        if not OPTUNA_AVAILABLE:
            raise ImportError("Optuna is required for optimization. Install with: pip install optuna")
        
        config = config or {}
        self.n_trials = config.get('n_trials', 100)
        self.timeout = config.get('timeout', 3600)
        self.sampler_type = config.get('sampler', 'tpe')
        self.cv_folds = config.get('cv_folds', 5)
        self.n_jobs = config.get('n_jobs', 1)
        self.direction = config.get('direction', 'maximize')
        
        # åˆ›å»ºé‡‡æ ·å™¨
        if self.sampler_type == 'tpe':
            self.sampler = TPESampler(seed=42)
        elif self.sampler_type == 'random':
            self.sampler = RandomSampler(seed=42)
        elif self.sampler_type == 'cmaes':
            self.sampler = CmaEsSampler(seed=42)
        else:
            raise ValueError(f"æœªçŸ¥é‡‡æ ·å™¨: {self.sampler_type}")
        
        # åˆ›å»ºpruner (æå‰ç»ˆæ­¢è¡¨ç°å·®çš„è¯•éªŒ)
        self.pruner = MedianPruner(n_startup_trials=10, n_warmup_steps=5)
        
        logger.info(f"Optunaä¼˜åŒ–å™¨åˆå§‹åŒ–: {self.n_trials} trials, {self.sampler_type} sampler")
    
    def optimize_xgboost_classification(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        dates: Optional[pd.Series] = None,
        metric: str = 'auc'
    ) -> Dict[str, Any]:
        """
        ä¼˜åŒ–XGBooståˆ†ç±»å™¨è¶…å‚æ•°
        
        Parameters
        ----------
        X : DataFrame
            ç‰¹å¾æ•°æ®
        y : Series
            åˆ†ç±»æ ‡ç­¾
        dates : Series, optional
            æ—¥æœŸåºåˆ—ï¼ˆç”¨äºæ—¶é—´åºåˆ—åˆ‡åˆ†ï¼‰
        metric : str, default='auc'
            ä¼˜åŒ–æŒ‡æ ‡ ('auc', 'f1')
        
        Returns
        -------
        result : dict
            åŒ…å« best_params, best_score, n_trials, study
        """
        logger.info("="*80)
        logger.info("å¼€å§‹XGBooståˆ†ç±»å™¨è¶…å‚æ•°ä¼˜åŒ–")
        logger.info("="*80)
        
        def objective(trial):
            # å®šä¹‰æœç´¢ç©ºé—´ - ğŸ”§ ä¿®å¤: åŠ å¼ºæ­£åˆ™åŒ–çº¦æŸï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 500),
                'max_depth': trial.suggest_int('max_depth', 3, 4),  # ğŸ”§ ä»3-10æ”¹ä¸º3-4
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 0.8),  # ğŸ”§ ä»0.6-1.0æ”¹ä¸º0.6-0.8
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),  # ğŸ”§ ä»0.6-1.0æ”¹ä¸º0.6-0.8
                'min_child_weight': trial.suggest_int('min_child_weight', 5, 15),  # ğŸ”§ ä»1-10æ”¹ä¸º5-15
                'gamma': trial.suggest_float('gamma', 1.0, 5.0),  # ğŸ”§ ä»0-5æ”¹ä¸º1-5
                'reg_alpha': trial.suggest_float('reg_alpha', 3.0, 10.0),  # ğŸ”§ ä»0-10æ”¹ä¸º3-10
                'reg_lambda': trial.suggest_float('reg_lambda', 5.0, 10.0),  # ğŸ”§ ä»0-10æ”¹ä¸º5-10
                'random_state': 42,
                'verbosity': 0,
                'n_jobs': 1  # é¿å…åµŒå¥—å¹¶è¡Œ
            }
            
            # æ—¶é—´åºåˆ—äº¤å‰éªŒè¯
            tscv = TimeSeriesSplit(n_splits=self.cv_folds)
            cv_scores = []
            
            for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X)):
                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
                
                # è®­ç»ƒæ¨¡å‹
                model = xgb.XGBClassifier(**params)
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    verbose=False
                )
                
                # è¯„ä¼°
                y_pred_proba = model.predict_proba(X_val)[:, 1]
                if metric == 'auc':
                    score = roc_auc_score(y_val, y_pred_proba)
                else:
                    from sklearn.metrics import f1_score
                    y_pred = (y_pred_proba >= 0.5).astype(int)
                    score = f1_score(y_val, y_pred)
                
                cv_scores.append(score)
                
                # æŠ¥å‘Šä¸­é—´ç»“æœï¼ˆç”¨äºpruningï¼‰
                trial.report(score, fold_idx)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥æå‰ç»ˆæ­¢
                if trial.should_prune():
                    raise optuna.TrialPruned()
            
            return np.mean(cv_scores)
        
        # åˆ›å»ºstudyå¹¶ä¼˜åŒ–
        study = optuna.create_study(
            direction=self.direction,
            sampler=self.sampler,
            pruner=self.pruner
        )
        
        study.optimize(
            objective,
            n_trials=self.n_trials,
            timeout=self.timeout,
            n_jobs=self.n_jobs,
            show_progress_bar=True
        )
        
        logger.info(f"âœ… XGBooståˆ†ç±»ä¼˜åŒ–å®Œæˆ:")
        logger.info(f"  æœ€ä¼˜{metric.upper()}: {study.best_value:.4f}")
        logger.info(f"  æœ€ä¼˜å‚æ•°:")
        for key, value in study.best_params.items():
            logger.info(f"    {key}: {value}")
        logger.info(f"  æ€»è¯•éªŒæ¬¡æ•°: {len(study.trials)}")
        logger.info(f"  å‰ªæè¯•éªŒæ•°: {len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED])}")
        
        return {
            'best_params': study.best_params,
            'best_score': study.best_value,
            'n_trials': len(study.trials),
            'n_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),
            'study': study
        }
    
    def optimize_xgboost_regression(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        dates: Optional[pd.Series] = None,
        metric: str = 'r2'
    ) -> Dict[str, Any]:
        """
        ä¼˜åŒ–XGBoostå›å½’å™¨è¶…å‚æ•°
        
        Parameters
        ----------
        X : DataFrame
            ç‰¹å¾æ•°æ®
        y : Series
            å›å½’ç›®æ ‡
        dates : Series, optional
            æ—¥æœŸåºåˆ—
        metric : str, default='r2'
            ä¼˜åŒ–æŒ‡æ ‡ ('r2', 'mse', 'mae')
        
        Returns
        -------
        result : dict
            åŒ…å« best_params, best_score, n_trials, study
        """
        logger.info("="*80)
        logger.info("å¼€å§‹XGBoostå›å½’å™¨è¶…å‚æ•°ä¼˜åŒ–")
        logger.info("="*80)
        
        def objective(trial):
            # ğŸ”§ ä¿®å¤: åŠ å¼ºæ­£åˆ™åŒ–çº¦æŸï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 500),
                'max_depth': trial.suggest_int('max_depth', 3, 4),  # ğŸ”§ ä»3-10æ”¹ä¸º3-4
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 0.8),  # ğŸ”§ ä»0.6-1.0æ”¹ä¸º0.6-0.8
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),  # ğŸ”§ ä»0.6-1.0æ”¹ä¸º0.6-0.8
                'min_child_weight': trial.suggest_int('min_child_weight', 5, 15),  # ğŸ”§ ä»1-10æ”¹ä¸º5-15
                'gamma': trial.suggest_float('gamma', 1.0, 5.0),  # ğŸ”§ ä»0-5æ”¹ä¸º1-5
                'reg_alpha': trial.suggest_float('reg_alpha', 3.0, 10.0),  # ğŸ”§ ä»0-10æ”¹ä¸º3-10
                'reg_lambda': trial.suggest_float('reg_lambda', 5.0, 10.0),  # ğŸ”§ ä»0-10æ”¹ä¸º5-10
                'random_state': 42,
                'verbosity': 0,
                'n_jobs': 1
            }
            
            tscv = TimeSeriesSplit(n_splits=self.cv_folds)
            cv_scores = []
            
            for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X)):
                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
                
                model = xgb.XGBRegressor(**params)
                model.fit(
                    X_train, y_train,
                    eval_set=[(X_val, y_val)],
                    verbose=False
                )
                
                y_pred = model.predict(X_val)
                
                if metric == 'r2':
                    score = r2_score(y_val, y_pred)
                elif metric == 'mse':
                    score = -mean_squared_error(y_val, y_pred)  # è´Ÿå€¼å› ä¸ºè¦æœ€å¤§åŒ–
                else:  # mae
                    from sklearn.metrics import mean_absolute_error
                    score = -mean_absolute_error(y_val, y_pred)
                
                cv_scores.append(score)
                trial.report(score, fold_idx)
                
                if trial.should_prune():
                    raise optuna.TrialPruned()
            
            return np.mean(cv_scores)
        
        study = optuna.create_study(
            direction=self.direction,
            sampler=self.sampler,
            pruner=self.pruner
        )
        
        study.optimize(
            objective,
            n_trials=self.n_trials,
            timeout=self.timeout,
            n_jobs=self.n_jobs,
            show_progress_bar=True
        )
        
        logger.info(f"âœ… XGBoostå›å½’ä¼˜åŒ–å®Œæˆ:")
        logger.info(f"  æœ€ä¼˜{metric.upper()}: {study.best_value:.4f}")
        logger.info(f"  æœ€ä¼˜å‚æ•°:")
        for key, value in study.best_params.items():
            logger.info(f"    {key}: {value}")
        logger.info(f"  æ€»è¯•éªŒæ¬¡æ•°: {len(study.trials)}")
        
        return {
            'best_params': study.best_params,
            'best_score': study.best_value,
            'n_trials': len(study.trials),
            'n_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),
            'study': study
        }
    
    def optimize_lightgbm_classification(
        self,
        X: pd.DataFrame,
        y: pd.Series,
        dates: Optional[pd.Series] = None,
        metric: str = 'auc'
    ) -> Dict[str, Any]:
        """
        ä¼˜åŒ–LightGBMåˆ†ç±»å™¨è¶…å‚æ•°
        """
        logger.info("="*80)
        logger.info("å¼€å§‹LightGBMåˆ†ç±»å™¨è¶…å‚æ•°ä¼˜åŒ–")
        logger.info("="*80)
        
        def objective(trial):
            # ğŸ”§ ä¿®å¤: åŠ å¼ºæ­£åˆ™åŒ–çº¦æŸï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            params = {
                'n_estimators': trial.suggest_int('n_estimators', 100, 500),
                'max_depth': trial.suggest_int('max_depth', 3, 4),  # ğŸ”§ ä»3-10æ”¹ä¸º3-4
                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),
                'subsample': trial.suggest_float('subsample', 0.6, 0.8),  # ğŸ”§ ä»0.6-1.0æ”¹ä¸º0.6-0.8
                'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 0.8),  # ğŸ”§ ä»0.6-1.0æ”¹ä¸º0.6-0.8
                'min_child_samples': trial.suggest_int('min_child_samples', 20, 100),  # ğŸ”§ ä»5-100æ”¹ä¸º20-100
                'reg_alpha': trial.suggest_float('reg_alpha', 3.0, 10.0),  # ğŸ”§ ä»0-10æ”¹ä¸º3-10
                'reg_lambda': trial.suggest_float('reg_lambda', 5.0, 10.0),  # ğŸ”§ ä»0-10æ”¹ä¸º5-10
                'random_state': 42,
                'verbosity': -1,
                'n_jobs': 1
            }
            
            tscv = TimeSeriesSplit(n_splits=self.cv_folds)
            cv_scores = []
            
            for fold_idx, (train_idx, val_idx) in enumerate(tscv.split(X)):
                X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
                y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
                
                model = lgb.LGBMClassifier(**params)
                model.fit(X_train, y_train)
                
                y_pred_proba = model.predict_proba(X_val)[:, 1]
                
                if metric == 'auc':
                    score = roc_auc_score(y_val, y_pred_proba)
                else:
                    from sklearn.metrics import f1_score
                    y_pred = (y_pred_proba >= 0.5).astype(int)
                    score = f1_score(y_val, y_pred)
                
                cv_scores.append(score)
                trial.report(score, fold_idx)
                
                if trial.should_prune():
                    raise optuna.TrialPruned()
            
            return np.mean(cv_scores)
        
        study = optuna.create_study(
            direction=self.direction,
            sampler=self.sampler,
            pruner=self.pruner
        )
        
        study.optimize(
            objective,
            n_trials=self.n_trials,
            timeout=self.timeout,
            n_jobs=self.n_jobs,
            show_progress_bar=True
        )
        
        logger.info(f"âœ… LightGBMåˆ†ç±»ä¼˜åŒ–å®Œæˆ:")
        logger.info(f"  æœ€ä¼˜{metric.upper()}: {study.best_value:.4f}")
        logger.info(f"  æœ€ä¼˜å‚æ•°: {study.best_params}")
        logger.info(f"  æ€»è¯•éªŒæ¬¡æ•°: {len(study.trials)}")
        
        return {
            'best_params': study.best_params,
            'best_score': study.best_value,
            'n_trials': len(study.trials),
            'n_pruned': len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),
            'study': study
        }
    
    def visualize_optimization(self, study: optuna.Study, save_path: Optional[str] = None):
        """
        å¯è§†åŒ–ä¼˜åŒ–è¿‡ç¨‹
        
        Parameters
        ----------
        study : optuna.Study
            å®Œæˆçš„studyå¯¹è±¡
        save_path : str, optional
            ä¿å­˜è·¯å¾„å‰ç¼€
        """
        try:
            import matplotlib.pyplot as plt
            from optuna.visualization import (
                plot_optimization_history,
                plot_param_importances,
                plot_parallel_coordinate,
                plot_slice
            )
            
            logger.info("ç”ŸæˆOptunaå¯è§†åŒ–å›¾è¡¨...")
            
            # ä¼˜åŒ–å†å²
            fig1 = plot_optimization_history(study)
            if save_path:
                fig1.write_html(f"{save_path}_history.html")
            
            # å‚æ•°é‡è¦æ€§
            fig2 = plot_param_importances(study)
            if save_path:
                fig2.write_html(f"{save_path}_importance.html")
            
            # å¹³è¡Œåæ ‡å›¾
            fig3 = plot_parallel_coordinate(study)
            if save_path:
                fig3.write_html(f"{save_path}_parallel.html")
            
            logger.info(f"âœ… å¯è§†åŒ–å®Œæˆï¼Œä¿å­˜è‡³: {save_path}_*.html")
            
        except Exception as e:
            logger.warning(f"å¯è§†åŒ–å¤±è´¥: {e}")
