# -*- coding: utf-8 -*-
"""
æ‰¹é‡è®­ç»ƒæ¨¡å—
æ”¯æŒä¸€æ¬¡æ€§è®­ç»ƒå¤šåªè‚¡ç¥¨ï¼Œä½¿ç”¨çœŸæ­£çš„æ¨ªæˆªé¢quantileç­–ç•¥
"""

import logging
import pandas as pd
import numpy as np
from typing import List, Dict, Tuple, Optional

logger = logging.getLogger(__name__)


def prepare_batch_training_data(
    symbols: List[str],
    price_frames: Dict[str, pd.DataFrame],
    qfq_frames: Dict[str, pd.DataFrame],
    builder,
    market_generator,
    board_generator,
    market_returns: pd.DataFrame,
    batch_size: int,
    prediction_period: int,
    classification_strategy: str,
    label_quantile: float,
    label_min_samples: int,
    label_negative_quantile: Optional[float],
    label_threshold: float,
    enable_neutral_band: bool,
    label_neutral_quantile: Optional[float],
    use_market_baseline: bool,
    use_industry_neutral: bool,
    market_column: str = 'MKT',
    **kwargs
) -> Tuple[List[pd.DataFrame], List[Tuple[str, str]]]:
    """
    æ‰¹é‡å‡†å¤‡è®­ç»ƒæ•°æ®ï¼ˆä¸€æ¬¡å¤„ç†batch_sizeåªè‚¡ç¥¨ï¼‰
    
    Parameters
    ----------
    symbols : List[str]
        è‚¡ç¥¨ä»£ç åˆ—è¡¨
    price_frames : Dict[str, pd.DataFrame]
        ä¸å¤æƒä»·æ ¼æ•°æ®å­—å…¸
    qfq_frames : Dict[str, pd.DataFrame]
        å‰å¤æƒä»·æ ¼æ•°æ®å­—å…¸
    builder : UnifiedFeatureBuilder
        ç‰¹å¾æ„å»ºå™¨
    market_generator : MarketFactorGenerator
        å¸‚åœºå› å­ç”Ÿæˆå™¨
    board_generator : BoardFeatureGenerator
        æ¿å—ç‰¹å¾ç”Ÿæˆå™¨
    market_returns : pd.DataFrame
        å¸‚åœºæ”¶ç›Šæ•°æ®
    batch_size : int
        æ¯æ‰¹å¤„ç†çš„è‚¡ç¥¨æ•°é‡
    prediction_period : int
        é¢„æµ‹å‘¨æœŸ
    classification_strategy : str
        åˆ†ç±»ç­–ç•¥
    label_quantile : float
        ä¸Šåˆ†ä½æ•°
    label_min_samples : int
        æœ€å°æ ·æœ¬æ•°
    label_negative_quantile : float or None
        ä¸‹åˆ†ä½æ•°ï¼ˆæ˜ç¡®è´Ÿç±»æˆ–ä¸­æ€§åŒºï¼‰
    label_threshold : float
        æ ·æœ¬ä¸è¶³æ—¶å›é€€çš„ç»å¯¹æ”¶ç›Šé˜ˆå€¼
    enable_neutral_band : bool
        æ˜¯å¦å¯ç”¨ä¸­æ€§åŒº
    label_neutral_quantile : float or None
        ä¸­æ€§åŒºä¸Šç•Œ
    use_market_baseline : bool
        æ˜¯å¦å‡å»å¸‚åœºåŸºå‡†æ„å»ºè¶…é¢æ”¶ç›Š
    use_industry_neutral : bool
        æ˜¯å¦åšè¡Œä¸šä¸­æ€§
    market_column : str
        å¸‚åœºåŸºå‡†åˆ—åï¼Œé»˜è®¤ MKT
    
    Returns
    -------
    batch_results : List[pd.DataFrame]
        æ¯æ‰¹çš„è®­ç»ƒæ•°æ®
    failed_symbols : List[Tuple[str, str]]
        å¤±è´¥çš„è‚¡ç¥¨åŠåŸå› 
    """
    from src.ml.training.toolkit import add_labels_corrected
    
    batch_results = []
    failed_symbols = []
    
    # å°†è‚¡ç¥¨åˆ†æ‰¹
    num_batches = (len(symbols) + batch_size - 1) // batch_size
    
    logger.info("=" * 80)
    logger.info(f"æ‰¹é‡è®­ç»ƒæ¨¡å¼å¯åŠ¨")
    logger.info("=" * 80)
    logger.info(f"æ€»è‚¡ç¥¨æ•°: {len(symbols)}")
    logger.info(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
    logger.info(f"æ‰¹æ¬¡æ•°é‡: {num_batches}")
    logger.info(f"æ ‡ç­¾ç­–ç•¥: {classification_strategy} (æ¨ªæˆªé¢quantile)")
    logger.info(f"  ä¸Šåˆ†ä½æ•°: {label_quantile:.2f}")
    if label_negative_quantile is not None:
        logger.info(f"  ä¸‹åˆ†ä½æ•°: {label_negative_quantile:.2f}")
    logger.info(f"  æ¯æ—¥æœ€å°æ ·æœ¬: {label_min_samples}")
    logger.info(f"  å›é€€é˜ˆå€¼: {label_threshold:.3f}")
    logger.info(f"  å¸‚åœºåŸºå‡†: {'å¯ç”¨' if use_market_baseline else 'å…³é—­'}")
    logger.info(f"  è¡Œä¸šä¸­æ€§: {'å¯ç”¨' if use_industry_neutral else 'å…³é—­'}")
    if enable_neutral_band:
        logger.info(f"  ä¸­æ€§åŒºå¯ç”¨, ä¸Šç•Œ: {label_neutral_quantile}")
    
    for batch_idx in range(num_batches):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, len(symbols))
        batch_symbols = symbols[start_idx:end_idx]
        
        logger.info("")
        logger.info(f"æ‰¹æ¬¡ {batch_idx + 1}/{num_batches}: å¤„ç† {len(batch_symbols)} åªè‚¡ç¥¨")
        logger.info(f"  èŒƒå›´: {start_idx + 1}-{end_idx}/{len(symbols)}")
        
        # æ”¶é›†è¿™æ‰¹è‚¡ç¥¨çš„æ‰€æœ‰ç‰¹å¾æ•°æ®
        batch_features = []
        batch_qfq_prices = []
        batch_raw_prices = []
        
        for symbol in batch_symbols:
            if symbol not in price_frames or symbol not in qfq_frames:
                logger.warning(f"  {symbol}: è·³è¿‡ - ä»·æ ¼æ•°æ®ç¼ºå¤±")
                failed_symbols.append((symbol, 'price_data_missing'))
                continue
            
            try:
                # æ„å»ºç‰¹å¾
                features_df = builder.build_features_from_dataframe(
                    price_frames[symbol], symbol
                )
                
                if features_df is None or len(features_df) == 0:
                    logger.warning(f"  {symbol}: è·³è¿‡ - ç‰¹å¾æ„å»ºå¤±è´¥")
                    failed_symbols.append((symbol, 'feature_build_failed'))
                    continue
                
                # æ·»åŠ å¸‚åœºç‰¹å¾
                if market_generator is not None and market_returns is not None:
                    try:
                        market_enriched = market_generator.add_market_features(
                            price_frames[symbol].copy(),
                            symbol,
                            market_returns
                        )
                        candidate_cols = ['MKT'] + market_generator.get_feature_names()
                        available_cols = [
                            col for col in candidate_cols
                            if col in market_enriched.columns
                        ]
                        if available_cols:
                            market_slice = market_enriched.reset_index()[['date'] + available_cols]
                            features_df = features_df.merge(market_slice, on='date', how='left')
                    except Exception as market_exc:
                        logger.warning(f"  {symbol}: å¸‚åœºç‰¹å¾æ·»åŠ å¤±è´¥ - {market_exc}")
                
                # æ·»åŠ symbolåˆ—
                features_df['symbol'] = symbol
                
                # æ·»åŠ æ¿å—ç‰¹å¾
                if board_generator is not None:
                    try:
                        features_df = board_generator.add_board_feature(
                            features_df, symbol_col='symbol'
                        )
                    except Exception as board_exc:
                        logger.warning(f"  {symbol}: æ¿å—ç‰¹å¾æ·»åŠ å¤±è´¥ - {board_exc}")
                
                # ç¡®ä¿æœ‰dateåˆ—
                if 'date' not in features_df.columns:
                    if features_df.index.name == 'date' or isinstance(features_df.index, pd.DatetimeIndex):
                        features_df = features_df.reset_index()
                        if 'index' in features_df.columns and 'date' not in features_df.columns:
                            features_df.rename(columns={'index': 'date'}, inplace=True)
                    else:
                        logger.warning(f"  {symbol}: è·³è¿‡ - ç¼ºå°‘dateåˆ—")
                        failed_symbols.append((symbol, 'no_date_column'))
                        continue
                
                # å‡†å¤‡ä»·æ ¼æ•°æ®
                price_raw = price_frames[symbol].copy()
                if price_raw.index.name == 'date' or isinstance(price_raw.index, pd.DatetimeIndex):
                    price_raw = price_raw.reset_index()
                    if 'index' in price_raw.columns and 'date' not in price_raw.columns:
                        price_raw.rename(columns={'index': 'date'}, inplace=True)
                
                price_raw = price_raw[['date', 'close']].copy()
                price_raw['symbol'] = symbol
                
                price_adj = qfq_frames[symbol].copy()
                if 'date' not in price_adj.columns:
                    price_adj = price_adj.reset_index()
                
                price_adj['date'] = pd.to_datetime(price_adj['date'])
                price_adj = price_adj[['date', 'close']].copy()
                price_adj['symbol'] = symbol
                
                # ğŸ”§ å…³é”®ä¿®å¤1: ç¡®ä¿æ‰€æœ‰DataFrameéƒ½é‡ç½®ç´¢å¼•ï¼Œé¿å…åˆå¹¶æ—¶çš„ç´¢å¼•å†²çª
                features_df = features_df.reset_index(drop=True)
                price_adj = price_adj.reset_index(drop=True)
                price_raw = price_raw.reset_index(drop=True)
                
                # ğŸ”§ å…³é”®ä¿®å¤2: å»é™¤é‡å¤åˆ—åï¼Œé¿å…concatæ—¶çš„åˆ—ç´¢å¼•å†²çª
                if not features_df.columns.is_unique:
                    logger.warning(f"  {symbol}: æ£€æµ‹åˆ°é‡å¤åˆ—åï¼Œè‡ªåŠ¨å»é‡ï¼ˆä¿ç•™ç¬¬ä¸€ä¸ªï¼‰")
                    features_df = features_df.loc[:, ~features_df.columns.duplicated()]
                
                if not price_adj.columns.is_unique:
                    price_adj = price_adj.loc[:, ~price_adj.columns.duplicated()]
                
                if not price_raw.columns.is_unique:
                    price_raw = price_raw.loc[:, ~price_raw.columns.duplicated()]
                
                # æ”¶é›†åˆ°æ‰¹æ¬¡åˆ—è¡¨
                batch_features.append(features_df)
                batch_qfq_prices.append(price_adj)
                batch_raw_prices.append(price_raw)
                
            except Exception as exc:
                logger.error(f"  {symbol}: å¤„ç†å¤±è´¥ - {exc}", exc_info=False)
                failed_symbols.append((symbol, f'exception_{type(exc).__name__}'))
        
        if len(batch_features) == 0:
            logger.warning(f"  æ‰¹æ¬¡ {batch_idx + 1}: æ— æœ‰æ•ˆè‚¡ç¥¨ï¼Œè·³è¿‡")
            continue
        
        logger.info(f"  æ‰¹æ¬¡ {batch_idx + 1}: æˆåŠŸå‡†å¤‡ {len(batch_features)} åªè‚¡ç¥¨çš„ç‰¹å¾")
        
        # åˆå¹¶æ‰¹æ¬¡æ•°æ®
        try:
            combined_features = pd.concat(batch_features, ignore_index=True)
            combined_qfq = pd.concat(batch_qfq_prices, ignore_index=True)
            combined_raw = pd.concat(batch_raw_prices, ignore_index=True)
            
            logger.info(f"  æ‰¹æ¬¡ {batch_idx + 1}: åˆå¹¶æ•°æ®")
            logger.info(f"    ç‰¹å¾è®°å½•æ•°: {len(combined_features):,}")
            logger.info(f"    è‚¡ç¥¨æ•°/å¤©: {combined_features.groupby('date')['symbol'].nunique().describe()}")
            
            # æ‰¹é‡è®¡ç®—æ ‡ç­¾ï¼ˆè¿™é‡Œä¼šä½¿ç”¨æ¨ªæˆªé¢quantileï¼‰
            logger.info(f"  æ‰¹æ¬¡ {batch_idx + 1}: è®¡ç®—æ ‡ç­¾ï¼ˆæ¨ªæˆªé¢quantileï¼‰...")
            
            features_with_labels = add_labels_corrected(
                features_df=combined_features,
                price_data=combined_qfq,
                prediction_period=prediction_period,
                threshold=label_threshold,
                price_data_raw=combined_raw,
                classification_strategy=classification_strategy,
                quantile=label_quantile,
                min_samples_per_date=label_min_samples,
                negative_quantile=label_negative_quantile,
                enable_neutral_band=enable_neutral_band,
                neutral_quantile=label_neutral_quantile,
                market_returns=market_returns,
                use_market_baseline=use_market_baseline,
                market_column=market_column,
                use_industry_neutral=use_industry_neutral
            )
            
            if len(features_with_labels) == 0:
                logger.warning(f"  æ‰¹æ¬¡ {batch_idx + 1}: æ ‡ç­¾è®¡ç®—åæ— æœ‰æ•ˆæ•°æ®")
                continue
            
            # è¿‡æ»¤æç«¯å€¼
            extreme_mask = features_with_labels['label_reg'].abs() > 1.0
            if extreme_mask.sum() > 0:
                logger.info(f"  æ‰¹æ¬¡ {batch_idx + 1}: è¿‡æ»¤ {extreme_mask.sum()} æ¡æç«¯æ”¶ç›Šç‡")
                features_with_labels = features_with_labels[~extreme_mask]
            
            if len(features_with_labels) == 0:
                logger.warning(f"  æ‰¹æ¬¡ {batch_idx + 1}: è¿‡æ»¤åæ— æ•°æ®")
                continue
            
            logger.info(f"  æ‰¹æ¬¡ {batch_idx + 1}: âœ… å®Œæˆ")
            logger.info(f"    æœ€ç»ˆè®°å½•æ•°: {len(features_with_labels):,}")
            logger.info(f"    æ­£æ ·æœ¬ç‡: {features_with_labels['label_cls'].mean():.2%}")
            
            batch_results.append(features_with_labels)
            
        except Exception as exc:
            logger.error(f"  æ‰¹æ¬¡ {batch_idx + 1}: æ ‡ç­¾è®¡ç®—å¤±è´¥ - {exc}", exc_info=True)
            # å°†è¿™æ‰¹æ‰€æœ‰è‚¡ç¥¨æ ‡è®°ä¸ºå¤±è´¥
            for symbol in batch_symbols:
                if symbol not in [s for s, _ in failed_symbols]:
                    failed_symbols.append((symbol, 'label_calculation_failed'))
    
    logger.info("")
    logger.info(f"æ‰¹é‡è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ:")
    logger.info(f"  æˆåŠŸæ‰¹æ¬¡: {len(batch_results)}/{num_batches}")
    logger.info(f"  å¤±è´¥è‚¡ç¥¨: {len(failed_symbols)}")
    
    return batch_results, failed_symbols
